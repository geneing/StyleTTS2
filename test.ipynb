{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "# load packages\n",
    "import time\n",
    "import random\n",
    "import yaml\n",
    "from munch import Munch\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import librosa\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "from models import *\n",
    "from utils import *\n",
    "from text_utils import TextCleaner\n",
    "textclenaer = TextCleaner()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def length_to_mask(lengths):\n",
    "    mask = torch.arange(lengths.max()).unsqueeze(0).expand(lengths.shape[0], -1).type_as(lengths)\n",
    "    mask = torch.gt(mask+1, lengths.unsqueeze(1))\n",
    "    return mask\n",
    "\n",
    "# load phonemizer\n",
    "import phonemizer\n",
    "global_phonemizer = phonemizer.backend.EspeakBackend(language='en-us', preserve_punctuation=True,  with_stress=True)\n",
    "\n",
    "config = yaml.safe_load(open(\"Models/LJSpeech/config.yml\"))\n",
    "\n",
    "# load pretrained ASR model\n",
    "ASR_config = config.get('ASR_config', False)\n",
    "ASR_path = config.get('ASR_path', False)\n",
    "text_aligner = load_ASR_models(ASR_path, ASR_config)\n",
    "\n",
    "# load pretrained F0 model\n",
    "F0_path = config.get('F0_path', False)\n",
    "pitch_extractor = load_F0_models(F0_path)\n",
    "\n",
    "# load BERT model\n",
    "from Utils.PLBERT.util import load_plbert\n",
    "BERT_path = config.get('PLBERT_dir', False)\n",
    "plbert = load_plbert(BERT_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage = '''He began a sentence: “I am–” but when he was taken by surprise, every sentence became an adventure in the woods; as soon as he could no longer see the light of the clearing from which he’d entered, he would realize that the crumbs he’d dropped for bearings had been eaten by birds, silent deft darting things which he couldn’t quite see in the darkness but which were so numerous and swarming in their hunger that it seemed as if they were the darkness, as if the darkness weren’t uniform, weren’t an absence of light but a teeming corpuscular thing, and indeed when as a studious teenager he’d encountered the word “crepuscular” in McKay’s Treasury of English Verse, the corpuscles of biology had bled into his understanding of the word, so that for his entire adult life he’d seen in twilight a corpuscularity, as of the graininess of the high-speed film necessary for photography under conditions of low ambient light, as of a kind of sinister decay; and hence the panic of a man betrayed deep in the woods whose darkness was the darkness of starlings blotting out the sunset or black ants storming a dead opossum, a darkness that didn’t just exit but actively consumed the bearings that he’d sensibly established for himself, lest he be lost; but in the instant of realizing he was lost, time became marvelously slow and he discovered hitherto unguessed eternities in the space between one word and the next, or rather he became trapped in that space between one word and the next, or rather he became trapped in that space between words and could only stand and watch as time sped on without him, the thoughtless boyish part of him crashing on out of sight blindly through the woods while he, trapped, the grownup Al, watched in oddly impersonal suspense to see if the panic-stricken little boy might, despite no longer knowing where he was or at what point he’d entered the woods of this sentence, still manage to blunder into the clearing where Enid was waiting for him, unaware of any woods–“packing my suitcase,” he heard himself say. '''\n",
    "passage += '''Of all the problems which have been submitted to my friend, Mr.\n",
    "Sherlock Holmes, for solution during the years of our intimacy, there\n",
    "were only two which I was the means of introducing to his notice—that\n",
    "of Mr. Hatherley’s thumb, and that of Colonel Warburton’s madness. Of\n",
    "these the latter may have afforded a finer field for an acute and\n",
    "original observer, but the other was so strange in its inception and so\n",
    "dramatic in its details that it may be the more worthy of being placed\n",
    "upon record, even if it gave my friend fewer openings for those\n",
    "deductive methods of reasoning by which he achieved such remarkable\n",
    "results. The story has, I believe, been told more than once in the\n",
    "newspapers, but, like all such narratives, its effect is much less\n",
    "striking when set forth _en bloc_ in a single half-column of print than\n",
    "when the facts slowly evolve before your own eyes, and the mystery\n",
    "clears gradually away as each new discovery furnishes a step which\n",
    "leads on to the complete truth. At the time the circumstances made a\n",
    "deep impression upon me, and the lapse of two years has hardly served\n",
    "to weaken the effect.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He began a sentence: “I am–” but when he was taken by surprise, every sentence became an adventure in the woods; as soon as he could no longer see the light of the clearing from which he’d entered, he would realize that the crumbs he’d dropped for bearings had been eaten by birds, silent deft darting things which he couldn’t quite see in the darkness but which were so numerous and swarming in their hunger that it seemed as if they were the darkness, as if the darkness weren’t uniform, weren’t an absence of light but a teeming corpuscular thing, and indeed when as a studious teenager he’d encountered the word “crepuscular” in McKay’s Treasury of English Verse, the corpuscles of biology had bled into his understanding of the word, so that for his entire adult life he’d seen in twilight a corpuscularity, as of the graininess of the high-speed film necessary for photography under conditions of low ambient light, as of a kind of sinister decay; and hence the panic of a man betrayed deep in the woods whose darkness was the darkness of starlings blotting out the sunset or black ants storming a dead opossum, a darkness that didn’t just exit but actively consumed the bearings that he’d sensibly established for himself, lest he be lost; but in the instant of realizing he was lost, time became marvelously slow and he discovered hitherto unguessed eternities in the space between one word and the next, or rather he became trapped in that space between one word and the next, or rather he became trapped in that space between words and could only stand and watch as time sped on without him, the thoughtless boyish part of him crashing on out of sight blindly through the woods while he, trapped, the grownup Al, watched in oddly impersonal suspense to see if the panic-stricken little boy might, despite no longer knowing where he was or at what point he’d entered the woods of this sentence, still manage to blunder into the clearing where Enid was waiting for him, unaware of any woods–“packing my suitcase,” he heard himself say. Of all the problems which have been submitted to my friend, Mr.\n",
      "Sherlock Holmes, for solution during the years of our intimacy, there\n",
      "were only two which I was the means of introducing to his notice—that\n",
      "of Mr. Hatherley’s thumb, and that of Colonel Warburton’s madness. Of\n",
      "these the latter may have afforded a finer field for an acute and\n",
      "original observer, but the other was so strange in its inception and so\n",
      "dramatic in its details that it may be the more worthy of being placed\n",
      "upon record, even if it gave my friend fewer openings for those\n",
      "deductive methods of reasoning by which he achieved such remarkable\n",
      "results. The story has, I believe, been told more than once in the\n",
      "newspapers, but, like all such narratives, its effect is much less\n",
      "striking when set forth _en bloc_ in a single half-column of print than\n",
      "when the facts slowly evolve before your own eyes, and the mystery\n",
      "clears gradually away as each new discovery furnishes a step which\n",
      "leads on to the complete truth. At the time the circumstances made a\n",
      "deep impression upon me, and the lapse of two years has hardly served\n",
      "to weaken the effect.\n"
     ]
    }
   ],
   "source": [
    "print(passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phoneme_tokenize(s):\n",
    "    # text = passage.split('.')[0].strip()\n",
    "    text = s.strip()\n",
    "\n",
    "    # text = text.replace('\"', '')\n",
    "    ps = global_phonemizer.phonemize([text])\n",
    "    ps = word_tokenize(ps[0])\n",
    "    ps = ' '.join(ps)\n",
    "    tokens = textclenaer(ps)\n",
    "    tokens.insert(0, 0)\n",
    "    return tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t He began a sentence: “I am–” but when he was taken by surprise \n",
      "\n",
      "\n",
      "\t\t  every sentence became an adventure in the woods \n",
      "\n",
      "\n",
      "\t\t  as soon as he could no longer see the light of the clearing from which he’d entered \n",
      "\n",
      "\n",
      "\t\t  he would realize that the crumbs he’d dropped for bearings had been eaten by birds \n",
      "\n",
      "\n",
      "\t\t  silent deft darting things which he couldn’t quite see in the darkness but which were so numerous and swarming in their hunger that it seemed as if they were the darkness \n",
      "\n",
      "\n",
      "\t\t  as if the darkness weren’t uniform \n",
      "\n",
      "\n",
      "\t\t  weren’t an absence of light but a teeming corpuscular thing \n",
      "\n",
      "\n",
      "\t\t  and indeed when as a studious teenager he’d encountered the word “crepuscular” in McKay’s Treasury of English Verse \n",
      "\n",
      "\n",
      "\t\t  the corpuscles of biology had bled into his understanding of the word \n",
      "\n",
      "\n",
      "\t\t  so that for his entire adult life he’d seen in twilight a corpuscularity \n",
      "\n",
      "\n",
      "\t\t  as of the graininess of the high-speed film necessary for photography under conditions of low ambient light \n",
      "\n",
      "\n",
      "\t\t  as of a kind of sinister decay \n",
      "\n",
      "\n",
      "\t\t  and hence the panic of a man betrayed deep in the woods whose darkness was the darkness of starlings blotting out the sunset or black ants storming a dead opossum \n",
      "\n",
      "\n",
      "\t\t  a darkness that didn’t just exit but actively consumed the bearings that he’d sensibly established for himself \n",
      "\n",
      "\n",
      "\t\t  lest he be lost \n",
      "\n",
      "\n",
      "\t\t  but in the instant of realizing he was lost \n",
      "\n",
      "\n",
      "\t\t  time became marvelously slow and he discovered hitherto unguessed eternities in the space between one word and the next \n",
      "\n",
      "\n",
      "\t\t  or rather he became trapped in that space between one word and the next \n",
      "\n",
      "\n",
      "\t\t  or rather he became trapped in that space between words and could only stand and watch as time sped on without him \n",
      "\n",
      "\n",
      "\t\t  the thoughtless boyish part of him crashing on out of sight blindly through the woods while he \n",
      "\n",
      "\n",
      "\t\t  trapped \n",
      "\n",
      "\n",
      "\t\t  the grownup Al \n",
      "\n",
      "\n",
      "\t\t  watched in oddly impersonal suspense to see if the panic-stricken little boy might \n",
      "\n",
      "\n",
      "\t\t  despite no longer knowing where he was or at what point he’d entered the woods of this sentence \n",
      "\n",
      "\n",
      "\t\t  still manage to blunder into the clearing where Enid was waiting for him \n",
      "\n",
      "\n",
      "\t\t  unaware of any woods–“packing my suitcase \n",
      "\n",
      "\n",
      "\t\t ” he heard himself say. \n",
      "\n",
      "\n",
      "72\n",
      "48\n",
      "83\n",
      "82\n",
      "174\n",
      "39\n",
      "61\n",
      "123\n",
      "76\n",
      "85\n",
      "108\n",
      "33\n",
      "168\n",
      "116\n",
      "20\n",
      "49\n",
      "126\n",
      "77\n",
      "124\n",
      "93\n",
      "7\n",
      "16\n",
      "86\n",
      "97\n",
      "77\n",
      "46\n",
      "28\n",
      "Of all the problems which have been submitted to my friend, Mr.Sherlock Holmes, for solution during the years of our intimacy, therewere only two which I was the means of introducing to his notice—thatof Mr. Hatherley’s thumb, and that of Colonel Warburton’s madness. \n",
      "\n",
      "\n",
      "290\n",
      "Ofthese the latter may have afforded a finer field for an acute andoriginal observer, but the other was so strange in its inception and sodramatic in its details that it may be the more worthy of being placedupon record, even if it gave my friend fewer openings for thosedeductive methods of reasoning by which he achieved such remarkableresults. \n",
      "\n",
      "\n",
      "384\n",
      "The story has, I believe, been told more than once in thenewspapers, but, like all such narratives, its effect is much lessstriking when set forth _en bloc_ in a single half-column of print thanwhen the facts slowly evolve before your own eyes, and the mysteryclears gradually away as each new discovery furnishes a step whichleads on to the complete truth. \n",
      "\n",
      "\n",
      "390\n",
      "At the time the circumstances made adeep impression upon me, and the lapse of two years has hardly servedto weaken the effect. \n",
      "\n",
      "\n",
      "139\n"
     ]
    }
   ],
   "source": [
    "# Function to split text into tokens, if the text generates more than 512 tokens (downstream network cannot process more than 512 tokens at once)\n",
    "# We first split the text into pieces by punctuation. \n",
    "# If the pieces are still too long, we'll split on spaces into equal size pieces.\n",
    "# If it's still too long, we truncate the tokens, to avoid the network failing.\n",
    "def subtokenize(s):\n",
    "    txt = re.split(r\"[,;]\", s)\n",
    "    if len(txt)>1:\n",
    "        token_list=[]\n",
    "        for t in txt:\n",
    "            token_list += subtokenize(t)\n",
    "        return token_list\n",
    "    else:\n",
    "        token = phoneme_tokenize(txt[0])\n",
    "        if len(token) < 511:\n",
    "            print('\\t\\t',txt[0],'\\n\\n')\n",
    "            return [token]\n",
    "        else:\n",
    "            t = re.split(r\"[ ]\", txt[0])\n",
    "            length = len(t) # number of words\n",
    "            if length == 1:\n",
    "                token = phoneme_tokenize(t[0])\n",
    "                if len(token) > 511:\n",
    "                    print(\"still too long {token}\")\n",
    "                    return [token[:511]]\n",
    "                else :\n",
    "                    return [token]\n",
    "            else:\n",
    "                return subtokenize(\" \".join(t[0:length//2])) + subtokenize(\" \".join(t[length//2:]))\n",
    "\n",
    "\n",
    "\n",
    "def tokenize_text(passage):\n",
    "    for s in sent_tokenize(passage):\n",
    "        s=s.replace('\\n','').replace('\\r','')\n",
    "        tokens = phoneme_tokenize(s)\n",
    "        if len(tokens) < 511:\n",
    "            print(s,'\\n\\n')\n",
    "            tokens = [tokens]\n",
    "        else:\n",
    "            tokens=subtokenize(s)\n",
    "\n",
    "        for t in tokens:\n",
    "            print(len(t))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blah,', 'blah']\n"
     ]
    }
   ],
   "source": [
    "a=re.split(r\"[ ]\", 'blah, blah')\n",
    "len(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2170"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"testtext.txt\", 'r') as sourcefile:\n",
    "    text = sourcefile.read()\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'I took it up and glanced at it.', '“Mr. Victor Hatherley, hydraulic engineer, 16A, Victoria Street (3rd floor).”', 'That was the name, style, and abode of my morning visitor.', '“I regret that I have kept you waiting,” said I, sitting down in my library-chair.', '“You are fresh from a night journey, I understand, which is in itself a monotonous occupation.”', '“I saw the teeming sea; I saw daybreak and nightfall; I saw the multitudes of America; I saw a silvery cobweb in the center of a black pyramid; I saw a splintered labyrinth (it was London); I saw, close up, unending eyes watching themselves in me as in a mirror; I saw all the mirrors on earth and none of them reflected me; I saw in a backyard of Soler Street the same tiles that thirty years before I’d seen in the entrance of a house in Fray Bentos; I saw bunches of grapes, snow, tobacco, lodes of metal, steam; I saw convex equatorial deserts and each one of their grains of sand; I saw a woman in Inverness whom I shall never forget; I saw her tangled hair, her tall figure, I saw the cancer in her breast; I saw a ring of baked mud in a sidewalk, where before there had been a tree; I saw a summer house in Adrogué and a copy of the first English translation of Pliny — Philemon Holland’s — and all at the same time saw each letter on each page (as a boy, I used to marvel that the letters in a closed book did not get scrambled and lost overnight); I saw a sunset in Querétaro that seemed to reflect the colour of a rose in Bengal; I saw my empty bedroom; I saw in a closet in Alkmaar a terrestrial globe between two mirrors that multiplied it endlessly; I saw horses with flowing manes on a shore of the Caspian Sea at dawn; I saw the delicate bone structure of a hand; I saw the survivors of a battle sending out picture postcards; I saw in a showcase in Mirzapur a pack of Spanish playing cards; I saw the slanting shadows of ferns on a greenhouse floor; I saw tigers, pistons, bison, tides, and armies; I saw all the ants on the planet; I saw a Persian astrolabe; I saw in the drawer of a writing table (and the handwriting made me tremble) unbelievable, obscene, detailed letters, which Beatriz had written to Carlos Argentino; I saw a monument I worshipped in the Chacarita cemetery; I saw the rotted dust and bones that had once deliciously been Beatriz Viterbo; I saw the circulation of my own dark blood; I saw the coupling of love and the modification of death; I saw the Aleph from every point and angle, and in the Aleph I saw the earth and in the earth the Aleph and in the Aleph the earth; I saw my own face and my own bowels; I saw your face; and I felt dizzy and wept, for my eyes had seen that secret and conjectured object whose name is common to all men but which no man has looked upon — the unimaginable universe.”']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('sentencizer') \n",
    "doc = nlp(text)\n",
    "sentences = [sent.text.strip() for sent in doc.sents]\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[“, Mr., Victor, Hatherley, ,, hydraulic, engineer, ,, 16A, ,, Victoria, Street, (, 3rd, floor, ), ., ”]\n"
     ]
    }
   ],
   "source": [
    "t=list(nlp.tokenizer(sentences[2]))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“\n",
      "Mr.\n",
      "Victor\n",
      "Hatherley\n",
      ",\n",
      "hydraulic\n",
      "engineer\n",
      ",\n",
      "16A\n",
      ",\n",
      "Victoria\n",
      "Street\n",
      "(\n",
      "3rd\n",
      "floor\n",
      ")\n",
      ".\n",
      "”\n"
     ]
    }
   ],
   "source": [
    "for w in t:\n",
    "    print(w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
