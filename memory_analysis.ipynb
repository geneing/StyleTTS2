{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import glob\n",
    "import re\n",
    "import sys\n",
    "import yaml\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import click\n",
    "from socket import gethostname\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# load packages\n",
    "import random\n",
    "import yaml\n",
    "from munch import Munch\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import librosa\n",
    "\n",
    "from models import *\n",
    "from meldataset import build_dataloader\n",
    "from utils import *\n",
    "from losses import *\n",
    "from optimizers import build_optimizer\n",
    "import time\n",
    "\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import LoggerType\n",
    "from accelerate import DistributedDataParallelKwargs\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import logging\n",
    "from accelerate.logging import get_logger\n",
    "logger = get_logger(__name__, log_level=\"DEBUG\")\n",
    "\n",
    "class MEM_PROBE(object):\n",
    "    def __init__(self):\n",
    "        self.last_mem = torch.cuda.memory_allocated()\n",
    "\n",
    "    def __call__(self):\n",
    "        current_mem = torch.cuda.memory_allocated()\n",
    "        mem_delta = current_mem - self.last_mem\n",
    "        self.last_mem = current_mem\n",
    "        print(f\"MEM:{sys._getframe(1).f_code.co_filename}:{sys._getframe(1).f_lineno} {mem_delta/(1024*1024*1024):.2f} : {current_mem/(1024*1024*1024):.2f} GB\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/rhome/eingerman/Projects/DeepLearning/TTS/StyleTTS2/Models/tensors.pt\", \"rb\") as f:\n",
    "    (y_rec, wav)=torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 46800]) torch.Size([4, 46800])\n"
     ]
    }
   ],
   "source": [
    "# y_rec = y_rec[:,:,:8000]\n",
    "# wav = wav[:,:8000]\n",
    "\n",
    "print(y_rec.shape, wav.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/wavlm-base-plus were not used when initializing WavLMModel: ['encoder.pos_conv_embed.conv.weight_g', 'encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing WavLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing WavLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of WavLMModel were not initialized from the model checkpoint at microsoft/wavlm-base-plus and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = yaml.safe_load(open(\"Configs/config_libritts_espeak.yml\"))\n",
    "\n",
    "device = \"cuda:0\"\n",
    "model_params = recursive_munch(config['model_params'])\n",
    "ASR_config = config.get('ASR_config', False)\n",
    "ASR_path = config.get('ASR_path', False)\n",
    "text_aligner = load_ASR_models(ASR_path, ASR_config)\n",
    "F0_path = config.get('F0_path', False)\n",
    "pitch_extractor = load_F0_models(F0_path)\n",
    "from Utils.PLBERT.util import load_plbert\n",
    "BERT_path = config.get('PLBERT_dir', False)\n",
    "plbert = load_plbert(BERT_path)\n",
    "model = build_model(model_params, text_aligner, pitch_extractor, plbert)\n",
    "\n",
    "scheduler_params = {\n",
    "    \"max_lr\": float(config['optimizer_params'].get('lr', 1e-4)),\n",
    "    \"pct_start\": float(config['optimizer_params'].get('pct_start', 0.0)),\n",
    "    \"epochs\": 200,\n",
    "    \"steps_per_epoch\": 1000,\n",
    "}\n",
    "optimizer = build_optimizer({key: model[key].parameters() for key in model},\n",
    "                                scheduler_params_dict= {key: scheduler_params.copy() for key in model},\n",
    "                            lr=float(config['optimizer_params'].get('lr', 1e-4)))\n",
    "\n",
    "\n",
    "gl = GeneratorLoss(model.mpd, model.msd).to(device) \n",
    "dl = DiscriminatorLoss(model.mpd, model.msd).to(device)\n",
    "\n",
    "sr = config['preprocess_params'].get('sr', 24000)\n",
    "wl = WavLMLoss(model_params.slm.model, \n",
    "                model.wd, \n",
    "                sr, \n",
    "                model_params.slm.sr).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    base_momentum: 0.85\n",
      "    betas: (0.8500000000061685, 0.99)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-09\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.0001\n",
      "    lr: 0.0001\n",
      "    max_lr: 0.0001\n",
      "    max_momentum: 0.95\n",
      "    maximize: False\n",
      "    min_lr: 0.0001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "bert_encoder AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    base_momentum: 0.85\n",
      "    betas: (0.8500000000061685, 0.99)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-09\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.0001\n",
      "    lr: 0.0001\n",
      "    max_lr: 0.0001\n",
      "    max_momentum: 0.95\n",
      "    maximize: False\n",
      "    min_lr: 0.0001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "predictor AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    base_momentum: 0.85\n",
      "    betas: (0.8500000000061685, 0.99)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-09\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.0001\n",
      "    lr: 0.0001\n",
      "    max_lr: 0.0001\n",
      "    max_momentum: 0.95\n",
      "    maximize: False\n",
      "    min_lr: 0.0001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "decoder AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    base_momentum: 0.85\n",
      "    betas: (0.8500000000061685, 0.99)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-09\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.0001\n",
      "    lr: 0.0001\n",
      "    max_lr: 0.0001\n",
      "    max_momentum: 0.95\n",
      "    maximize: False\n",
      "    min_lr: 0.0001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "text_encoder AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    base_momentum: 0.85\n",
      "    betas: (0.8500000000061685, 0.99)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-09\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.0001\n",
      "    lr: 0.0001\n",
      "    max_lr: 0.0001\n",
      "    max_momentum: 0.95\n",
      "    maximize: False\n",
      "    min_lr: 0.0001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "predictor_encoder AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    base_momentum: 0.85\n",
      "    betas: (0.8500000000061685, 0.99)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-09\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.0001\n",
      "    lr: 0.0001\n",
      "    max_lr: 0.0001\n",
      "    max_momentum: 0.95\n",
      "    maximize: False\n",
      "    min_lr: 0.0001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "style_encoder AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    base_momentum: 0.85\n",
      "    betas: (0.8500000000061685, 0.99)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-09\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.0001\n",
      "    lr: 0.0001\n",
      "    max_lr: 0.0001\n",
      "    max_momentum: 0.95\n",
      "    maximize: False\n",
      "    min_lr: 0.0001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "diffusion AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    base_momentum: 0.85\n",
      "    betas: (0.8500000000061685, 0.99)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-09\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.0001\n",
      "    lr: 0.0001\n",
      "    max_lr: 0.0001\n",
      "    max_momentum: 0.95\n",
      "    maximize: False\n",
      "    min_lr: 0.0001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "text_aligner AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    base_momentum: 0.85\n",
      "    betas: (0.8500000000061685, 0.99)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-09\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.0001\n",
      "    lr: 0.0001\n",
      "    max_lr: 0.0001\n",
      "    max_momentum: 0.95\n",
      "    maximize: False\n",
      "    min_lr: 0.0001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "pitch_extractor AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    base_momentum: 0.85\n",
      "    betas: (0.8500000000061685, 0.99)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-09\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.0001\n",
      "    lr: 0.0001\n",
      "    max_lr: 0.0001\n",
      "    max_momentum: 0.95\n",
      "    maximize: False\n",
      "    min_lr: 0.0001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "mpd AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    base_momentum: 0.85\n",
      "    betas: (0.8500000000061685, 0.99)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-09\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.0001\n",
      "    lr: 0.0001\n",
      "    max_lr: 0.0001\n",
      "    max_momentum: 0.95\n",
      "    maximize: False\n",
      "    min_lr: 0.0001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "msd AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    base_momentum: 0.85\n",
      "    betas: (0.8500000000061685, 0.99)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-09\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.0001\n",
      "    lr: 0.0001\n",
      "    max_lr: 0.0001\n",
      "    max_momentum: 0.95\n",
      "    maximize: False\n",
      "    min_lr: 0.0001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "wd AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    base_momentum: 0.85\n",
      "    betas: (0.8500000000061685, 0.99)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-09\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.0001\n",
      "    lr: 0.0001\n",
      "    max_lr: 0.0001\n",
      "    max_momentum: 0.95\n",
      "    maximize: False\n",
      "    min_lr: 0.0001\n",
      "    weight_decay: 0.0001\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# for k, v in optimizer.optimizers.items():\n",
    "#     print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 0.31 : 0.63 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 0.15 : 0.78 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 0.00 : 0.78 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 0.00 : 0.78 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 -0.00 : 0.78 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 0.00 : 0.78 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 0.00 : 0.78 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 0.00 : 0.78 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 0.00 : 0.78 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 0.00 : 0.78 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 0.00 : 0.78 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 0.00 : 0.78 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 0.00 : 0.78 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 0.00 : 0.78 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 0.00 : 0.78 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 0.00 : 0.78 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 0.00 : 0.78 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 0.00 : 0.78 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 0.00 : 0.78 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 0.00 : 0.78 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 0.00 : 0.78 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 0.00 : 0.78 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:10 -0.02 : 0.76 GB\n",
      "MEM:/tmp/ipykernel_3837622/2444908502.py:12 -0.29 : 0.46 GB\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "w = wav.detach().unsqueeze(1).float()\n",
    "y = y_rec.detach()\n",
    "l = w.shape[2]\n",
    "idx = tuple(range(2048, l, 2048))\n",
    "\n",
    "memory_probe = MEM_PROBE()\n",
    "for w_chunk, y_chunk in zip(torch.tensor_split(w, idx, dim=2), torch.tensor_split(y, idx, dim=2)):\n",
    "    d_loss = dl(w_chunk, y_chunk)\n",
    "    d_loss.backward()\n",
    "memory_probe()\n",
    "\n",
    "\n",
    "# memory_probe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 2048]),\n",
       " torch.Size([4, 1, 1744])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.chunk(w, chunks=8, dim=2)\n",
    "l = w.shape[2]\n",
    "idx = tuple(range(2048, l, 2048))\n",
    "[t.shape for t in torch.tensor_split(w, idx, dim=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 2048,\n",
       " 4096,\n",
       " 6144,\n",
       " 8192,\n",
       " 10240,\n",
       " 12288,\n",
       " 14336,\n",
       " 16384,\n",
       " 18432,\n",
       " 20480,\n",
       " 22528,\n",
       " 24576,\n",
       " 26624,\n",
       " 28672,\n",
       " 30720,\n",
       " 32768,\n",
       " 34816,\n",
       " 36864,\n",
       " 38912,\n",
       " 40960,\n",
       " 43008,\n",
       " 45056)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminators.0.convs.0.bias : 32\n",
      "discriminators.0.convs.0.weight_g : 32\n",
      "discriminators.0.convs.0.weight_v : 160\n",
      "discriminators.0.convs.1.bias : 128\n",
      "discriminators.0.convs.1.weight_g : 128\n",
      "discriminators.0.convs.1.weight_v : 20480\n",
      "discriminators.0.convs.2.bias : 512\n",
      "discriminators.0.convs.2.weight_g : 512\n",
      "discriminators.0.convs.2.weight_v : 327680\n",
      "discriminators.0.convs.3.bias : 1024\n",
      "discriminators.0.convs.3.weight_g : 1024\n",
      "discriminators.0.convs.3.weight_v : 2621440\n",
      "discriminators.0.convs.4.bias : 1024\n",
      "discriminators.0.convs.4.weight_g : 1024\n",
      "discriminators.0.convs.4.weight_v : 5242880\n",
      "discriminators.0.conv_post.bias : 1\n",
      "discriminators.0.conv_post.weight_g : 1\n",
      "discriminators.0.conv_post.weight_v : 3072\n",
      "discriminators.1.convs.0.bias : 32\n",
      "discriminators.1.convs.0.weight_g : 32\n",
      "discriminators.1.convs.0.weight_v : 160\n",
      "discriminators.1.convs.1.bias : 128\n",
      "discriminators.1.convs.1.weight_g : 128\n",
      "discriminators.1.convs.1.weight_v : 20480\n",
      "discriminators.1.convs.2.bias : 512\n",
      "discriminators.1.convs.2.weight_g : 512\n",
      "discriminators.1.convs.2.weight_v : 327680\n",
      "discriminators.1.convs.3.bias : 1024\n",
      "discriminators.1.convs.3.weight_g : 1024\n",
      "discriminators.1.convs.3.weight_v : 2621440\n",
      "discriminators.1.convs.4.bias : 1024\n",
      "discriminators.1.convs.4.weight_g : 1024\n",
      "discriminators.1.convs.4.weight_v : 5242880\n",
      "discriminators.1.conv_post.bias : 1\n",
      "discriminators.1.conv_post.weight_g : 1\n",
      "discriminators.1.conv_post.weight_v : 3072\n",
      "discriminators.2.convs.0.bias : 32\n",
      "discriminators.2.convs.0.weight_g : 32\n",
      "discriminators.2.convs.0.weight_v : 160\n",
      "discriminators.2.convs.1.bias : 128\n",
      "discriminators.2.convs.1.weight_g : 128\n",
      "discriminators.2.convs.1.weight_v : 20480\n",
      "discriminators.2.convs.2.bias : 512\n",
      "discriminators.2.convs.2.weight_g : 512\n",
      "discriminators.2.convs.2.weight_v : 327680\n",
      "discriminators.2.convs.3.bias : 1024\n",
      "discriminators.2.convs.3.weight_g : 1024\n",
      "discriminators.2.convs.3.weight_v : 2621440\n",
      "discriminators.2.convs.4.bias : 1024\n",
      "discriminators.2.convs.4.weight_g : 1024\n",
      "discriminators.2.convs.4.weight_v : 5242880\n",
      "discriminators.2.conv_post.bias : 1\n",
      "discriminators.2.conv_post.weight_g : 1\n",
      "discriminators.2.conv_post.weight_v : 3072\n",
      "discriminators.3.convs.0.bias : 32\n",
      "discriminators.3.convs.0.weight_g : 32\n",
      "discriminators.3.convs.0.weight_v : 160\n",
      "discriminators.3.convs.1.bias : 128\n",
      "discriminators.3.convs.1.weight_g : 128\n",
      "discriminators.3.convs.1.weight_v : 20480\n",
      "discriminators.3.convs.2.bias : 512\n",
      "discriminators.3.convs.2.weight_g : 512\n",
      "discriminators.3.convs.2.weight_v : 327680\n",
      "discriminators.3.convs.3.bias : 1024\n",
      "discriminators.3.convs.3.weight_g : 1024\n",
      "discriminators.3.convs.3.weight_v : 2621440\n",
      "discriminators.3.convs.4.bias : 1024\n",
      "discriminators.3.convs.4.weight_g : 1024\n",
      "discriminators.3.convs.4.weight_v : 5242880\n",
      "discriminators.3.conv_post.bias : 1\n",
      "discriminators.3.conv_post.weight_g : 1\n",
      "discriminators.3.conv_post.weight_v : 3072\n",
      "discriminators.4.convs.0.bias : 32\n",
      "discriminators.4.convs.0.weight_g : 32\n",
      "discriminators.4.convs.0.weight_v : 160\n",
      "discriminators.4.convs.1.bias : 128\n",
      "discriminators.4.convs.1.weight_g : 128\n",
      "discriminators.4.convs.1.weight_v : 20480\n",
      "discriminators.4.convs.2.bias : 512\n",
      "discriminators.4.convs.2.weight_g : 512\n",
      "discriminators.4.convs.2.weight_v : 327680\n",
      "discriminators.4.convs.3.bias : 1024\n",
      "discriminators.4.convs.3.weight_g : 1024\n",
      "discriminators.4.convs.3.weight_v : 2621440\n",
      "discriminators.4.convs.4.bias : 1024\n",
      "discriminators.4.convs.4.weight_g : 1024\n",
      "discriminators.4.convs.4.weight_v : 5242880\n",
      "discriminators.4.conv_post.bias : 1\n",
      "discriminators.4.conv_post.weight_g : 1\n",
      "discriminators.4.conv_post.weight_v : 3072\n",
      "Total: 41105770\n"
     ]
    }
   ],
   "source": [
    "total=0\n",
    "for name, param in model.mpd.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        total += param.numel()\n",
    "        print(f\"{name} : {param.numel()}\")\n",
    "print(f\"Total: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEM:/tmp/ipykernel_3837622/1564091087.py:4 0.41 : 0.87 GB\n"
     ]
    }
   ],
   "source": [
    "for w_chunk, y_chunk in zip(torch.tensor_split(wav.detach(), idx, dim=1), torch.tensor_split(y_rec, idx, dim=2)):\n",
    "    loss_slm = wl(w_chunk.detach(), y_chunk)\n",
    "    # accelerator.backward(loss_slm, retain_graph=True)  #TODO: check if this is correct\n",
    "memory_probe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 4100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=tuple(range(2048, 4100, 2048))\n",
    "(t[:-1] + (4100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "tuple(4100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "styletts2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
